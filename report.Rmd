---
title: Fitting the TAM spectrum to empirical data
author: Mitsuhiro Nakamura
date: "`r Sys.time()`"
output:
  pdf_document:
    # latex_engine: lualatex
    toc: false
    number_sections: true
indent: true
header-includes: |
    \usepackage{indentfirst}
    \usepackage{listings}
    \usepackage[capitalize]{cleveref}
    \lstset{
      basicstyle={\small\ttfamily},
    }
---

```{r setup, include = FALSE}
library(doParallel)
library(ggplot2)
library(glue)
library(kableExtra)
library(knitr)
library(magrittr)
library(readr)
library(rstan)
library(stringr)
library(tibble)

knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cashe = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = '\\textwidth')
options(scipen = 100)
options(knitr.table.format = "latex")
theme_set(theme_light(base_size = 10) +
    theme(panel.spacing = unit(1, "lines")))

Ds <- read_csv( file.path("data-raw", "D.csv")
              , col_types = list(label = col_character(), D = col_integer())
              ) %>% tidyr::spread(label, D) %>% as.list

data_sets <- list()
data_sets$empirical <- local({
    c( "aurignacian_beads"
     , "neolithic_pottery"
     , "neolithic_ornaments"
     , "california_basketry"
     , "canoe_stylistic"
     , "canoe_functional"
     , "WNAI_technology"
     ) %>% purrr::map(function(name) {
        df <- read_csv( file.path("data-raw", glue(name, ".csv"))
                      , col_types = list( popularity = col_integer()
                                        , frequency = col_double()
                                        )
                      ) %>% dplyr::filter(!is.na(frequency) & frequency > 0)
        result <- list()
        result[[name]] <- list( label = gsub("_", " ", name) %>% {
                                   if (grepl("WNAI", .))
                                       identity(.)
                                   else
                                       str_to_sentence(.)
                                }
                              , D = Ds[[name]]
                              , table = df
                              )
        result
    }) %>% do.call(c, .)
})

data_sets$IBM <- local({
    c( paste("IBM_island_t=", 200000 - 1000 * 0:9, sep = "")
     , paste("IBM_lattice_t=", 200000 - 1000 * 0:9, sep = "")
     ) %>% purrr::map(function(name) {
        prefix <- sub("(IBM_\\w+)_.+", "\\1", name, perl = TRUE)
        suffix <- sub("IBM_\\w+_(.+)", "\\1", name, perl = TRUE)
        df <- read_csv( file.path("data-raw", glue(prefix, ".csv"))
                      , col_types = list( popularity = col_integer()
                                        , .default = col_double()
                                        )
                      )
        df <- df[, c("popularity", suffix)]
        colnames(df) <- c("popularity", "frequency")
        df <- df %>% dplyr::filter(!is.na(frequency) & frequency > 0)
        result <- list()
        result[[name]] <- list( label = gsub("_", " ", name) %>% {
                                   if (grepl("IBM", .))
                                       identity(.)
                                   else
                                       str_to_sentence(.)
                                }
                              , D = Ds[[prefix]]
                              , table = df
                              )
        result
    }) %>% do.call(c, .)
})

data_sets$IBM$IBM_island <- list (
      label = "IBM island"
    , D = Ds$IBM_island
    , table = data_sets$IBM[grepl("island", names(data_sets$IBM))] %>% purrr::map_dfr(~ .$table)
    )
data_sets$IBM[grepl("IBM_island_", names(data_sets$IBM))] <- NULL
data_sets$IBM$IBM_lattice <- list (
      label = "IBM lattice"
    , D = Ds$IBM_lattice
    , table = data_sets$IBM[grepl("lattice", names(data_sets$IBM))] %>% purrr::map_dfr(~ .$table)
    )
data_sets$IBM[grepl("IBM_lattice_", names(data_sets$IBM))] <- NULL

theory <- local({
    log_xi <- function(k, D, lambda, theta)
        -log(k) + k * log(lambda) + lgamma(D + 1) + lgamma(D + theta - k) - lgamma(D + 1 - k) - lgamma(D + theta)
    function(ks, D, lambda, theta)
    exp(log_xi(ks, D, lambda, theta)) / sum(exp(log_xi(1:D, D, lambda, theta)))
})
```

```{r mcmc, include = FALSE}
registerDoParallel(parallel::detectCores())

cache <- file.path("cache", "results_empirical.RData")
if (file.exists(cache)) {
    load(cache)
} else {
    model <- stan_model("model.stan")
    results_empirical <- foreach(data_set = data_sets$empirical) %dopar% sampling(
          model
        , control = list( adapt_delta = .998
                        , max_treedepth = 15
                        )
        , cores = 1
        , chains = 8
        , iter = 2000
        , warmup = 1000
        , data = list( l = nrow(data_set$table)
                     , k = data_set$table$popularity
                     , m = data_set$table$frequency
                     , D = data_set$D
                     )
        )
    names(results_empirical) <- names(data_sets$empirical)
    save(results_empirical, file = cache)
}

cache <- file.path("cache", "results_IBM.RData")
if (file.exists(cache)) {
    load(cache)
} else {
    model <- stan_model("model.stan")
    results_IBM <- foreach(data_set = data_sets$IBM) %dopar% sampling(
          model
        , control = list( adapt_delta = .998
                        , max_treedepth = 15
                        )
        , cores = 1
        , chains = 8
        , iter = 2000
        , warmup = 1000
        , data = list( l = nrow(data_set$table)
                     , k = data_set$table$popularity
                     , m = data_set$table$frequency
                     , D = data_set$D
                     )
        )
    names(results_IBM) <- names(data_sets$IBM)
    save(results_IBM, file = cache)
}
```

# Statistical model

Let $k_1^m = \{k_1, k_2, \cdots, k_m\}$ be popularities of cultural traits $1,
2, \cdots, m$, respectively. We assume that they are i.i.d. and distributed
according to the weights given by the TAM spectrum; the probability to observe
$k_i = k$ ($k = 1, 2, \cdots, D$) is given by
\begin{equation} \label{eq:normalized-TAM}
p(k_i = k \mid \mu, b, h, \beta, \eta) = \frac{\xi_k}{\sum_{k=1}^D \xi_k}.
\end{equation}
\Cref{eq:normalized-TAM} apparently has five parameters (without known $D$).
However, the TAM spectrum can be rewritten to
\begin{subequations}
\begin{equation}
\xi_k = C\frac{\lambda^k}{k} \prod_{i=1}^k \frac{D + 1 - i}{D + \theta - i}
      = C\frac{\lambda^k}{k} \frac{\Gamma(D + 1)\Gamma(D + \theta - k)}{\Gamma(D + 1 - k)\Gamma(D + \theta)}
\end{equation}
where
\begin{align}
C &= \frac{\mu^\prime}{\beta + \eta^\prime}(D-1), \\
\mu^\prime &= \frac{\mu}{b}, \\
\lambda &= 1 + \frac{\eta^\prime}{\beta},
\end{align}
and
\begin{align}
\theta &= \frac{1-\beta}{\beta}(D-1).
\end{align}
\end{subequations}
\noindent Thus, \cref{eq:normalized-TAM} actually has two parameters:
$\lambda$ and $\theta$. Note that $C$ is dropped due to normalization in
\cref{eq:normalized-TAM}, and $\beta$ and $\eta^\prime$ are recovered from
$D$, $\lambda$, and $\theta$ as
\begin{subequations}
\begin{equation}
\beta = \frac{D - 1}{D - 1 + \theta}
\end{equation}
and
\begin{equation}
\eta^\prime = \beta (\lambda - 1).
\end{equation}
\end{subequations}

Because we do not care about the index of each cultural trait in the
data $k_1^m$, the likelihood to observe a spectrum, i.e.
\begin{equation}
\label{eq:data-as-table}
S = \left\{ (k, m_k) \mid k \in \{1, 2, \cdots, D\}, m_k = \#\{k^\prime \in k_1^m \mid k^\prime = k\} \right\},
\end{equation}
is given by a multinomial distribution
\begin{equation}
\mathcal{L}(\lambda, \theta \mid S) = \frac{m!}{\prod_{k=1}^D m_k!} \prod_{k=1}^D p(k \mid \lambda, \theta)^{m_k},
\end{equation}
where $p(k \mid \lambda, \theta)$ is identical to \cref{eq:normalized-TAM}.
Note that $\sum_{k=1}^D m_k = m$ holds true.
Finally, the log-likelihood for the spectrum is given by
\begin{subequations}
\label{eq:log-likelihood}
\begin{align}
\ell(\lambda, \theta \mid S) =& -\sum_{k=1}^D m_k \log k + \sum_{k=1}^D m_k k
\log \lambda + m \log\Gamma(D + 1) + \sum_{k=1}^D m_k \log\Gamma(D + \theta - k) \nonumber \\
&- \sum_{k=1}^D m_k \log\Gamma(D + 1 - k) - m \log\Gamma(D + \theta)
- m \log Z(\lambda, \theta) + const.,
\end{align}
where
\begin{equation}
Z(\lambda, \theta) = \sum_{k=1}^D \frac{\lambda^k}{k}\frac{\Gamma(D + 1)\Gamma(D + \theta - k)}{\Gamma(D + 1 - k)\Gamma(D + \theta)}.
\end{equation}
\end{subequations}

# Bayesian MCMC

Using \cref{eq:log-likelihood}, we estimated parameters for each of
the empirical data sets (Aurignacian beads, Neolithic pottery, Neolithic
ornaments, California basketry, Canoe stylistic, Canoe functional, and WNAI
technology) by means of Bayesian MCMC.

To check the effect of population structure on the estimation using the TAM
model, we also estimated parameters for the artificial data sets extracted
from our IBM (IBM island and IBM lattice).
From each simulation result of IBM island and lattice used in the main text,
we took 10 population snapshots at time steps $191,000, 192,000, \cdots,
200,000$ and use the all snapshots for the check.

Performing MCMC, we use Stan, version 2.18.2, with which we employed NUTS
algorithm with tuning parameters \lstinline{adapt_delta = .998} and
\lstinline{max_treedepth = 15}.
We set the other tuning parameters to their default values. We run eight
chains of $2,000$ MCMC steps in which first $1,000$ warm-up steps were dropped
to calculate posterior distributions.
Listing \ref{lst:stan-code} shows the Stan code used for our estimation.
In our estimation, we fixed $D$ to the number of all sites or groups in each
empirical data set. For priors of $\lambda$ and $\theta$, we assumed half-Cauchy
distributions with scale parameter $5$.

\newpage
\lstinputlisting[label={lst:stan-code},caption={Stan code.}]{model.stan}
\newpage

# Results

\Cref{tab:summary-empirical,tab:summary-IBM} show the summaries of obtained
posterior distributions for the empirical and artificial data sets,
respectively.
For all the parameters in all the data sets, $\hat{R}$ is almost equal to $1$,
indicating that MCMC chains reached relaxation.
Moreover, the effective sample size, $n_{\rm eff}$, is sufficiently large for
all the cases.

\Cref{fig:plot-empirical,fig:plot-IBM} show the posterior predictions of TAM spectra for
the empirical and artificial data sets, respectively.
These predictions were obtained from \cref{eq:normalized-TAM} scaled by the
number of cultural traits and the posterior distributions of $\lambda$ and
$\theta$.

```{r summary_empirical}
summary_empirical <- results_empirical %>% purrr::map_dfr(function(fit) {
    df <- summary(fit)$summary %>% as_tibble %>% round(3)
    df <- df[1:5, c(1, 3:ncol(df))] %>%
        add_column( param = c( "$\\lambda$"
                             , "$\\theta$"
                             , "$\\beta$"
                             , "$\\eta^\\prime$"
                             , "$\\beta + \\eta^\\prime$"
                             )
                  , .before = TRUE
                  )
    colnames(df) <- c( "Parameter"
                     , "Mean"
                     , "SD"
                     , "2.5\\%"
                     , "25\\%"
                     , "50\\%"
                     , "75\\%"
                     , "97.5\\%"
                     , "$n_{\\rm eff}$"
                     , "$\\hat{R}$"
                     )
    df
})
write_csv(summary_empirical, file.path("cache", "summary_empirical.csv"))
knitr::kable(summary_empirical, escape = FALSE, booktabs = TRUE
            , label = "summary-empirical"
            , caption = "Summary statistics of posterior distributions."
            ) %>%
    group_rows("Aurignacian beads", 1, 5) %>%
    group_rows("Neolithic pottery", 6, 10) %>%
    group_rows("Neolithic ornaments", 11, 15) %>%
    group_rows("California basketry", 16, 20) %>%
    group_rows("Canoe stylistic", 21, 25) %>%
    group_rows("Canoe functional", 26, 30) %>%
    group_rows("WNAI technology", 31, 35)
```

```{r plot_empirical, fig.cap = "\\label{fig:plot-empirical}Posterior predictions of TAM specta: empirical data (black points), posterior means (red lines), and 95\\% credible intervals (transparent red ribbons)."}
empirical_df <- data_sets$empirical %>% purrr::map_dfr(function(data_set) {
  # data_set$table$popularity <- data_set$table$popularity / data_set$D
  # data_set$table$frequency <- data_set$table$frequency / sum(data_set$table$frequency)
    data_set$table %>% add_column(label = data_set$label, .before = TRUE)
})
empirical_df$label <- factor( empirical_df$label
                            , levels = data_sets$empirical %>% purrr::map_chr(~ .$label)
                            )
theoretical_df <- names(data_sets$empirical) %>% purrr::map_dfr(function(name) {
    data_set <- data_sets$empirical[[name]]
    D <- data_set$D
    ks <- 1:D
    scale <- sum(data_set$table$frequency)
    post_pred <- with(rstan::extract(results_empirical[[name]], c("lambda", "theta")), {
        purrr::map2(lambda, theta, function(lambda_, theta_) {
            scale * theory(ks, D, lambda_, theta_)
        }) %>% do.call(rbind, .)
    })
    tibble( label = data_sets$empirical[[name]]$label
          , popularity = ks
          , freq_mean = apply(post_pred, 2, mean)
          , freq_q025 = apply(post_pred, 2, function(.) quantile(., .025))
          , freq_q975 = apply(post_pred, 2, function(.) quantile(., .975))
          )
})
theoretical_df$label <- factor( theoretical_df$label
                              , levels = data_sets$empirical %>% purrr::map_chr(~ .$label)
                              )

ggplot(empirical_df, aes(x = popularity)) +
    facet_wrap(~ label, scales = "free") +
    geom_point(aes(y = frequency), size = .6) +
    geom_ribbon( aes(ymin = freq_q025, ymax = freq_q975)
               , data = theoretical_df
               , fill = "red"
               , alpha = .3
               ) +
    geom_line( aes(y = freq_mean)
             , data = theoretical_df
             , color = "red"
             ) +
  # scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  # scale_y_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    labs( x = "Popularity"
        , y = "Frequency"
        )
```

```{r summary_IBM}
summary_IBM <- results_IBM %>% purrr::map_dfr(function(fit) {
    df <- summary(fit)$summary %>% as_tibble %>% round(3)
    df <- df[1:5, c(1, 3:ncol(df))] %>%
        add_column( param = c( "$\\lambda$"
                             , "$\\theta$"
                             , "$\\beta$"
                             , "$\\eta^\\prime$"
                             , "$\\beta + \\eta^\\prime$"
                             )
                  , .before = TRUE
                  )
    colnames(df) <- c( "Parameter"
                     , "Mean"
                     , "SD"
                     , "2.5\\%"
                     , "25\\%"
                     , "50\\%"
                     , "75\\%"
                     , "97.5\\%"
                     , "$n_{\\rm eff}$"
                     , "$\\hat{R}$"
                     )
    df
})
write_csv(summary_IBM, file.path("cache", "summary_IBM.csv"))
knitr::kable(summary_IBM, escape = FALSE, booktabs = TRUE
            , label = "summary-IBM"
            , caption = "Summary statistics of posterior distributions."
            ) %>%
    group_rows("IBM island", 1, 5) %>%
    group_rows("IBM lattice", 6, 10)
```

```{r plot_IBM, fig.height = 2, fig.cap = "\\label{fig:plot-IBM}Posterior predictions of TAM specta: artificial data (black points), posterior means (red lines), and 95\\% credible intervals (transparent red ribbons)."}
empirical_df <- data_sets$IBM %>% purrr::map_dfr(function(data_set) {
  # data_set$table$popularity <- data_set$table$popularity / data_set$D
  # data_set$table$frequency <- data_set$table$frequency / sum(data_set$table$frequency)
    data_set$table %>% add_column(label = data_set$label, .before = TRUE)
})
empirical_df$label <- factor( empirical_df$label
                            , levels = data_sets$IBM %>% purrr::map_chr(~ .$label)
                            )
theoretical_df <- names(data_sets$IBM) %>% purrr::map_dfr(function(name) {
    data_set <- data_sets$IBM[[name]]
    D <- data_set$D
    ks <- 1:D
    scale <- sum(data_set$table$frequency) / 10
    post_pred <- with(rstan::extract(results_IBM[[name]], c("lambda", "theta")), {
        purrr::map2(lambda, theta, function(lambda_, theta_) {
            scale * theory(ks, D, lambda_, theta_)
        }) %>% do.call(rbind, .)
    })
    tibble( label = data_sets$IBM[[name]]$label
          , popularity = ks
          , freq_mean = apply(post_pred, 2, mean)
          , freq_q025 = apply(post_pred, 2, function(.) quantile(., .025))
          , freq_q975 = apply(post_pred, 2, function(.) quantile(., .975))
          )
})
theoretical_df$label <- factor( theoretical_df$label
                              , levels = data_sets$IBM %>% purrr::map_chr(~ .$label)
                              )

ggplot(empirical_df, aes(x = popularity)) +
    facet_wrap(~ label, scales = "free") +
    geom_point(aes(y = frequency), size = .6) +
    geom_ribbon( aes(ymin = freq_q025, ymax = freq_q975)
               , data = theoretical_df
               , fill = "red"
               , alpha = .3
               ) +
    geom_line( aes(y = freq_mean)
             , data = theoretical_df
             , color = "red"
             ) +
  # scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  # scale_y_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    labs( x = "Popularity"
        , y = "Frequency"
        )
```

<!-- vim: set fdm=syntax: -->
