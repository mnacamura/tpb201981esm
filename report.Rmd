---
title: Fitting the TAM spectrum to empirical data
author: Mitsuhiro Nakamura
date: "`r Sys.time()`"
output:
  pdf_document:
    # latex_engine: lualatex
    toc: false
    number_sections: true
    fig_width: 5
    fig_height: 3.09
indent: true
header-includes: |
    \usepackage{indentfirst}
    \usepackage{listings}
    \usepackage[capitalize]{cleveref}
    \lstset{
      basicstyle={\small\ttfamily},
    }
---

```{r setup, include = FALSE}
library(doParallel)
library(ggplot2)
library(glue)
library(kableExtra)
library(knitr)
library(magrittr)
library(readr)
library(rstan)
library(stringr)
library(tibble)

options(scipen = 100)
theme_set(theme_light(base_size = 10) +
    theme(panel.spacing = unit(1, "lines")))

data_sets <- local({
    Ds <- read_csv( file.path("data-raw", "D.csv")
                  , col_types = list(label = col_character(), D = col_integer())
                  ) %>% tidyr::spread(label, D) %>% as.list
    c( "aurignacian_beads"
     , "neolithic_pottery"
     , "neolithic_ornaments"
     , "california_basketry"
     , "canoe_stylistic"
     , "canoe_functional"
     , "WNAI_technology"
     ) %>% purrr::map(function(name) {
        df <- read_csv( file.path("data-raw", glue(name, ".csv"))
                      , col_types = list(.default = col_integer())
                      ) %>% dplyr::filter(!is.na(frequency) & frequency > 0)
        result <- list()
        result[[name]] <- list( label = gsub("_", " ", name) %>% {
                                   if (grepl("WNAI", .))
                                       identity(.)
                                   else
                                       str_to_sentence(.)
                                }
                              , D = Ds[[name]]
                              , data = df
                              )
        result
    }) %>% do.call(c, .)
})

to_samples <- function(data)
    with(data, do.call(c, mapply(rep, popularity, frequency)))
```

```{r mcmc, include = FALSE}
registerDoParallel(parallel::detectCores())

cache <- file.path("cache", "mcmc_results.RData")
if (file.exists(cache)) {
    load(cache)
} else {
    model <- stan_model("model.stan")
    results <- foreach(data_set = data_sets) %dopar% {
        ks <- data_set$data %>% to_samples
        sampling( model
                , control = list( adapt_delta = .998
                                , max_treedepth = 15
                                )
                , cores = 1
                , chains = 8
                , iter = 2000
                , warmup = 1000
                , data = list( M = length(ks)
                             , K = ks
                             , D = data_set$D
                             )
                )
    }
    names(results) <- names(data_sets)
    save(results, file = cache)
}
```

# Statistical model

Let $K_1^m = \{K_1, K_2, \cdots, K_m\}$ be popularities of cultural traits $1, 2,
\cdots, m$, respectively. Supposing that they are approximately i.i.d., the
probability to observe $K_i$ is, from the TAM spectrum, given by
\begin{equation}
\label{eq:normalized-TAM}
p(K_i \mid D, \mu, e, h, \beta, \eta) = \frac{\xi_{K_i}}{\sum_{k=1}^D \xi_k}.
\end{equation}
\Cref{eq:normalized-TAM} apparently has six paremeters. However, the TAM
spectrum can be rewritten to
\begin{subequations}
\begin{equation}
\xi_k = C\frac{\lambda^k}{k} \prod_{i=1}^k \frac{D + 1 - i}{D + \theta - i}
      = C\frac{\lambda^k}{k} \frac{\Gamma(D + 1)\Gamma(D + \theta - k)}{\Gamma(D + 1 - k)\Gamma(D + \theta)}
\end{equation}
where
\begin{align}
C &= \frac{\mu^\prime}{\beta + \eta^\prime}(D-1), \\
\mu^\prime &= \frac{\mu}{e}, \\
\lambda &= 1 + \frac{\eta^\prime}{\beta},
\end{align}
and
\begin{align}
\theta &= \frac{1-\beta}{\beta}(D-1).
\end{align}
\end{subequations}
\noindent Thus, \cref{eq:normalized-TAM} actually has three parameters: $D$,
$\lambda$, and $\theta$. Note that $C$ is dropped due to normalization in
\cref{eq:normalized-TAM}, and $\beta$ and $\eta^\prime$ are recovered from
$D$, $\lambda$, and $\theta$ as
\begin{subequations}
\begin{equation}
\beta = \frac{D - 1}{D - 1 + \theta}
\end{equation}
and
\begin{equation}
\eta^\prime = \beta (\lambda - 1).
\end{equation}
\end{subequations}
\noindent The log-likelihood for the data $K_1^m$ is given by
\begin{subequations}
\label{eq:log-likelihood}
\begin{align}
\ell(K_1^m \mid D, \lambda, \theta) =& -\sum_{i=1}^m \log K_i + \sum_{i=1}^m K_i
\log \lambda + m \log\Gamma(D + 1) + \sum_{i=1}^m \log\Gamma(D + \theta - K_i) \nonumber \\
&- \sum_{i=1}^m \log\Gamma(D + 1 - K_i) - m \log\Gamma(D + \theta)
- m \log Z(D, \lambda, \theta),
\end{align}
where
\begin{equation}
Z(D, \lambda, \theta) = \sum_{k=1}^D \frac{\lambda^k}{k}\frac{\Gamma(D + 1)\Gamma(D + \theta - k)}{\Gamma(D + 1 - k)\Gamma(D + \theta)}.
\end{equation}
\end{subequations}

# Bayesian MCMC

Using \cref{eq:log-likelihood}, we estimated the parameters for each of data
sets (Aurignacian beads, Neolithic pottery, Neolithic ornaments, California
basketry, Canoe stylistic, Canoe functional, and WNAI technology) by means of
Bayesian MCMC (Stan, version 2.18.2). Performing MCMC, we employed NUTS
algorithm with tuning parameters
\lstinline{adapt_delta = .998} and \lstinline{max_treedepth = 15}.
We set the other tuning parameters to their default values. We run eight
chains of $2,000$ MCMC steps in which first $1,000$ warm-up steps were dropped
to calculate posterior distributions.

Listing \ref{lst:stan-code} shows the Stan code used for our estimation.
In our estimation, we fixed $D$ to the number of all sites or groups in each
data set. For priors of $\lambda$ and $\theta$, we assumed half-Cauchy
distributions with scale parameter $5$.

\lstinputlisting[label={lst:stan-code},caption={Stan code.}]{model.stan}

# Results

\Cref{tab:mcmc-results} shows the summary of obtained posterior distributions
for the data sets. For all the parameters in all the data sets, $\hat{R}$ is
almost equal to $1$, indicating that MCMC chains reached relaxation. Moreover,
the effective sample size, $n_{\rm eff}$, is sufficiently large for all the
cases.

```{r results, echo = FALSE}
options(knitr.table.format = "latex")

summary_df <- results %>% purrr::map_dfr(function(fit) {
    df <- summary(fit)$summary %>% as_tibble %>% round(3)
    df <- df[1:5, c(1, 3:ncol(df))] %>%
        add_column( param = c( "$\\lambda$"
                             , "$\\theta$"
                             , "$\\beta$"
                             , "$\\eta^\\prime$"
                             , "$\\beta + \\eta^\\prime$"
                             )
                  , .before = TRUE
                  )
    colnames(df) <- c( "Parameter"
                     , "Mean"
                     , "SD"
                     , "2.5\\%"
                     , "25\\%"
                     , "50\\%"
                     , "75\\%"
                     , "97.5\\%"
                     , "$n_{\\rm eff}$"
                     , "$\\hat{R}$"
                     )
    df
})

knitr::kable(summary_df, escape = FALSE, booktabs = TRUE
            , label = "mcmc-results"
            , caption = "Summary statistics of posterior distributions."
            ) %>%
    group_rows("Aurignacian beads", 1, 5) %>%
    group_rows("Neolithic pottery", 6, 10) %>%
    group_rows("Neolithic ornaments", 11, 15) %>%
    group_rows("California basketry", 16, 20) %>%
    group_rows("Canoe stylistic", 21, 25) %>%
    group_rows("Canoe functional", 26, 30) %>%
    group_rows("WNAI technology", 31, 35)
```

\Cref{fig:plot} shows the posterior predictions of TAM spectra for the data
sets. These predictions were obtained from \cref{eq:normalized-TAM} scaled by
the number of cultural traits and the posterior distributions of $\lambda$
and $\theta$.

```{r plot, echo = FALSE, fig.cap = "\\label{fig:plot}Posterior predictions of TAM specta: empirical data (black points), posterior means (red lines), and 95\\% credible intervals (transparent red ribbons)."}
log_xi <- function(k, D, lambda, theta)
    -log(k) + k * log(lambda) +
        lgamma(D + 1) + lgamma(D + theta - k) - lgamma(D + 1 - k) - lgamma(D + theta)
theory <- function(ks, D, lambda, theta)
    exp(log_xi(ks, D, lambda, theta)) / sum(exp(log_xi(1:D, D, lambda, theta)))

empirical_df <- data_sets %>% purrr::map_dfr(function(data_set) {
    data_set$data %>% add_column(label = data_set$label, .before = TRUE)
})
empirical_df$label <- factor( empirical_df$label
                            , levels = data_sets %>% purrr::map_chr(~ .$label)
                            )
theoretical_df <- names(data_sets) %>% purrr::map_dfr(function(name) {
    data_set <- data_sets[[name]]
    fit <- 
    D <- data_set$D
    ks <- 1:D
    scale <- sum(data_set$data$frequency)
    post_pred <- with(rstan::extract(results[[name]], c("lambda", "theta")), {
        purrr::map2(lambda, theta, function(lambda_, theta_) {
            scale * theory(ks, D, lambda_, theta_)
        }) %>% do.call(rbind, .)
    })
    tibble( label = data_sets[[name]]$label
          , popularity = ks
          , freq_mean = apply(post_pred, 2, mean)
          , freq_q025 = apply(post_pred, 2, function(.) quantile(., .025))
          , freq_q975 = apply(post_pred, 2, function(.) quantile(., .975))
          )
})
theoretical_df$label <- factor( theoretical_df$label
                              , levels = data_sets %>% purrr::map_chr(~ .$label)
                              )

ggplot(empirical_df, aes(x = popularity)) +
    facet_wrap(~ label) +
    geom_point(aes(y = frequency), size = .6) +
    geom_ribbon( aes(ymin = freq_q025, ymax = freq_q975)
               , data = theoretical_df
               , fill = "red"
               , alpha = .3
               ) +
    geom_line( aes(y = freq_mean)
             , data = theoretical_df
             , color = "red"
             ) +
    scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    labs( x = "Popularity"
        , y = "Frequency"
        )
```

<!-- vim: set fdm=syntax: -->
